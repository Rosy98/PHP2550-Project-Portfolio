---
title: "Predicting Tracheostomy or Death in Infants with Severe Bronchopulmonary Dysplasia (BPD)"
subtitle: "Project 2: Regression Analysis [(Github Link)](https://github.com/Rosy98/PHP2550-Project-2)"
author: "Zihan Zhou"
date: "`r Sys.Date()`"
output: pdf_document
abstract: >
  \textbf{Aim:} This study aims to develop a model predicting the necessity and timing of tracheostomy in infants with severe Bronchopulmonary Dysplasia (BPD), using a rich dataset from the BPD Collaborative Registry. It examines demographic and clinical variables to identify significant predictors of tracheostomy or death. \par
  \textbf{Method:} Best Subset and Lasso regression were used to select variables for a logistic mixed-effects model, treating center as a random effect. Models were developed for two time points: 36 weeks and 44 weeks. The Brier score and AUC were employed for model assessment. \par
  \textbf{Result:} Both best subset and lasso regression models, using a mixed-effects approach, effectively identified factors influencing tracheotomy/death in infants with severe BPD. The Best Subset model at 36 weeks had a Brier Score of 0.0835 and an AUC of 0.8920, while the Lasso model at 44 weeks showed a Brier Score of 0.0923 and an AUC of 0.8853. However, calibration plots indicated some deviation in the 44-week models.\par
  \textbf{Conclusions:} The project reveals key factors impacting tracheotomy timing in severe BPD infants, highlighting birth metrics, respiratory support, and pulmonary hypertension medication. However, hese models need to be improved considering logistic regression assumptions such as linearity, outlier influence, and multicollinearity.

bibliography: Project2.bib
csl: ieee.csl
---

```{r setup, include=FALSE}
# Load library
library(knitr)
library(tidyr)
library(formatR)
library(kableExtra)
library(tidyverse)
library(ggplot2)
library(ggpubr)
library(stringr)
library(tidyverse)  
library(mice) 
library(pROC)
library(gtsummary)
library(leaps)
library(MASS)
library(car)
library(glmmLasso)
library(lme4)
opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE, echo = FALSE, fig.align = "center", fig.pos = "H")

```

```{r}
# Load data
load("project2_data.RData")
```


# 1. Introduction

Bronchopulmonary dysplasia (BPD) is the most common and one of the prognostically significant consequence of premature birth, affecting between 10,000 and 15,000 infants in the United States each year [@jensenEpidemiologyBronchopulmonaryDysplasia2014]. Despite advances in understanding its pathophysiology and the development of management strategies aimed at reducing its occurrence, the incidence of BPD has remained unchanged over the years [@stollTrendsCarePractices2015]. In cases of severe BPD, particularly Grade 3 (defined by 2001 NHLBI criteria), which requires ventilator dependence at 36 weeks of corrected gestational age, about 75% of these infants still need ventilator support upon hospital discharge, although not permanently. Tracheostomy, which is necessary for 2-4% of infants with BPD and up to 12% of those with severe or Grade 3 BPD, has several benefits such as stable airway maintenance, improved growth, and enhanced age-appropriate interactions. Early tracheostomy within four months, is associated with better outcomes, with infants receiving this procedure earlier (before 120 days) showing lower risks of death or neurodevelopmental impairment at 18-22 months [@demauroDevelopmentalOutcomesVery2014]. However, there is still no consensus on the optimal timing for tracheostomy. Previous studies utilizing large databases have successfully predicted the likelihood of tracheostomy or death using basic demographics and clinical diagnosis. However, these studies lacked detailed respiratory data and did not offer predictions at varying postmenstrual ages (PMA).

This project aims to create a regression model to predict the composite outcome of tracheostomy or death, thus guiding to determine the criteria and optimal timing for tracheostomy. Several models will be discussed and compared, including mixed-effect model, best subset selection, and lasso regression and ridge regression.

# 2. Data

## 2.1. Data sources

The data comes from the BPD Collaborative Registry, a multi-center consortium of interdisciplinary BPD programs located in the United States and Sweden formed to address gaps in evidence and promote research to enhance the care of children with severe forms of BPD. It specifically records data on infants born before 32 weeks of gestation and diagnosed with severe bronchopulmonary dysplasia (sBPD), as defined by the 2001 NHLBI criteria. This includes infants requiring a fractional inspired oxygen (FiO2) of more than 0.3 or any form of positive pressure ventilation at 36 weeks postmenstrual age (PMA). The registry gathers standard demographic and clinical information at key intervals: at birth, and at 36, 44 weeks PMA, and at discharge.

The data is pre-processed by converting the variables into the appropriate types as specified in the codebook. Out of 28 variables, 24 have missing values. Missing values in the variable of `center` are imputed based on the patients' record IDs. Center 21 only has one observation, so I impute it as center 1. Three duplicate records have also been removed, so the total 999 observations become 996 observations. Since `mat_race` is recorded differently between the data and the codebook, this variable will be excluded from future analyses.

Table 1 presents the challenge of missing data across various variables, with the extent of missingness showing significant variation. Notably, data collected at the 44-week corrected gestational age exhibit the most substantial missingness, which is most likely due to discharge. Additionally, the variable `any_surf`, indicating surfactant administration within the first 72 hours, displays a similar pattern of missingness to the 44-week variables. A significant number of missing entries are also found in the 36-week data. To address these concerns, multiple imputation will be implemented to enable a more robust and complete analysis.

```{r}
# check missing data
data_miss <- data[, -30] %>% dplyr::select(colnames(data[, -30][ ,colSums(is.na(data[, -30]))>0]))
# calculate the percentage of missing
data_miss_pct <- data.frame(cbind(Number = colSums(is.na(data_miss)), 
                                  Pct = paste0(round(100*colSums(is.na(data_miss))/nrow(data_miss), 2), "%"))) 

data_miss_pct <- data_miss_pct %>%
  arrange(desc(as.numeric(Number)))


data_miss_pct$Variable <- rownames(data_miss_pct)
rownames(data_miss_pct) <- NULL
data_miss_pct <- data_miss_pct[, c(3,1,2)] # reorder the column

# create table for summary of missing values
n <- nrow(data_miss_pct)
second <- n %/% 2

# Splitting the data frame into 3 parts
df1 <- data_miss_pct[1:second,]
df2 <- data_miss_pct[(second+1):n,]
rownames(df2) <- NULL
```

```{r}
kable(cbind(df1, df2), booktabs = T, escape = T, 
      caption = "Summary of Missing Values",
      align = "c") %>%
  kable_styling(latex_options = c("HOLD_position", "scale_down"))
```

## 2.2. Demographics and Clinical Diagnosis

```{r}
# change labels
data_demo <- data %>%
  mutate(
    mat_ethn = factor(mat_ethn, levels = c(1, 2), labels = c("Hispanic or Latino", "Not Hispanic or Latino")),
    del_method = factor(del_method, levels = c(1, 2), labels = c("Vaginal delivery", "Cesarean section")),
    ventilation_support_level.36 = factor(ventilation_support_level.36, levels = c(0, 1, 2), labels = c("No respiratory support or supplemental oxygen", "Non-invasive positive pressure", "Invasive positive pressure")),
    ventilation_support_level_modified.44 = factor(ventilation_support_level_modified.44, levels = c(0, 1, 2), labels = c("No respiratory support or supplemental oxygen", "Non-invasive positive pressure", "Invasive positive pressure")),
    Y = factor(Y, levels = c(0, 1), labels = c("No", "Yes"))
  )
```

Table 2 highlights the variability in tracheostomy rates and mortality rates among the centers. The tracheostomy rates has a range from 0% at Center 20 to 50.72% at Center 12, underscoring the significant disparities in practice. The higher rates of 50.72% and 41.54% in center 12 and 1 may suggest more aggressive treatment approaches or patient profiles requiring such interventions. In contrast, Centers 3, 7, and 16 have rates below 4%, which could reflect variations in demographics, protocols, or resources. The mortality rates ranges from 0% at Center 7, 16 and 20 to 20.29% at Center 12. The incidence of death is more rare compared to tracheostomy.

The pronounced differences across centers are statistically confirmed by a chi-squared test (p \< 0.001). Importantly, Center 2 accounts for over 60% of the patient cohort, highlighting a multilevel data structure and underscoring the importance of appropriately accounting for the `center` variable in analysis.

```{r}
center_trach_death <- data_demo %>%
  group_by(center) %>%
  summarise(
    With_Trach = sum(Trach == 1, na.rm = TRUE),
    death = sum(Death == "Yes", na.rm = TRUE),
    Total = n()
  ) %>%
  ungroup() %>%
  mutate(
    Tracheostomy_Percent = scales::percent(With_Trach / Total, accuracy = 0.01),
    Death_Percent = scales::percent(death / Total, accuracy = 0.01)) %>%
  dplyr::select(center, Total,  Tracheostomy_Percent, Death_Percent)

center_trach_death %>% kable(booktabs = T, escape = T, align = "c",
                       caption = "Tracheostomy and death Proportions across the Centers",
                       col.names = c("Center", "Total", "Tracheostomy Proportion", "Death Proportion")) %>%
  kable_styling(latex_options = c("HOLD_position"))

  
```

```{r, results='hide'}
trach_contingency_table <- table(data$center, data$Trach)

# Perform the Chi-squared test
chisq.test(trach_contingency_table)

death_contingency_table <- table(data$center, data$Death)

chisq.test(death_contingency_table)
```
The project's aim is to construct a regression model that predicts the combined outcome of tracheostomy or death. Consequently, a new composite variable, Y is introduced. In this binary outcome, patients are labeled '1' if they received a tracheostomy or succumbed to their condition, and '0' if they survived without undergoing a tracheostomy. This variable allows for a comprehensive analysis of both tracheostomy and patient survival. 

The demographic and clinical diagnosis data presented in Table 4 compare infants across this new composite outcome, revealing significant differences in several metrics in both birth metrics and follow-up assessments.

There was a notable reduction in birth weight compared to those without tracheostomy or death, with a median weight of 670 grams versus 760 grams, respectively, and this difference was statistically significant with a p-value smaller than 0.001. Additionally, 34% of the infants with tracheostomy or death were small for gestational age (SGA), a higher percentage than the 18% for infants with neither trac nor death (p\<0.001). Delivery method also differed significantly, with more infants in the trach/death group born via cesarean section (79% vs. 70%, p=0.017). No significant differences were observed in maternal ethnicity, chorioamnionitis, or gender.

In terms of the follow-up assessments, all of the metrics are significantly different accorss the two groups. A significant contrast was evident at 36 weeks of corrected gestational age, with 73% of the trach/death group requiring invasive positive pressure ventilation, compared to 17% not needing such support (p\<0.001) in the no trach/death group. By 44 weeks, the need for invasive positive pressure increased to 77% in the tracheostomy group versus just 15% (p\<0.001). The no trach/death group's non-invasive positive pressure decrease from 69% at 36 weeks to 28% at 44 weeks, while the trach/death group only dropped 6% from 22% to 16%. Additionally, infants with trach/death have higher median peak inspiratory pressures at both 36 and 44 weeks, and a greater proportion required medication for pulmonary hypertension at 44 weeks. The trach/death group also had significantly higher discharge ages. 

```{r}
# by trach
data_demo[, -c(1, 2, 28, 29)] %>%
  tbl_summary(by = Y, missing = "no",
              label = list(mat_ethn ~ "Maternal Ethnicity",
                           bw ~ "Birth Weight (g)",
                           ga ~ "Obstetrical Gestational Age",
                           blength ~ "Birth Length (cm)",
                           birth_hc ~ "Birth Head Hircumference (cm)",
                           gender ~ "Gender",
                           del_method ~ "Delivery Method",
                           prenat_ster ~ "Prenatal Corticosteroids",
                           com_prenat_ster ~ "Complete Prenatal Steroids",
                           mat_chorio ~ "Maternal Chorioamnionitis",
                           sga ~ "Small for Gestational Age",
                           any_surf ~ "Received Surfactant",
                           ventilation_support_level.36 ~ "Ventilation Support at 36 Weeks",
                           inspired_oxygen.36 ~ "Fraction of Inspired Oxygen at 36 Weeks",
                           weight_today.36 ~ "Weight at 36 Weeks",
                           p_delta.36 ~ "Peak Inspiratory Pressure (cm H2O) at 36 Weeks",
                           peep_cm_h2o_modified.36 ~ "Positive and Exploratory Pressure (cm H2O) at 36 Weeks",
                           med_ph.36 ~ "Medication for Pulmonary Hypertension at 36 Weeks",
                           ventilation_support_level_modified.44 ~ "Ventilation Support at 44 Weeks",
                           inspired_oxygen.44 ~ "Fraction of Inspired Oxygen at 44 Weeks",
                           weight_today.44 ~ "Weight at 44 Weeks",
                           p_delta.44 ~ "Peak Inspiratory Pressure (cm H2O) at 44 Weeks",
                           peep_cm_h2o_modified.44 ~ "Positive and Exploratory Pressure (cm H2O) at 44 Weeks",
                           med_ph.44 ~ "Medication for Pulmonary Hypertension at 44 Weeks",
                           hosp_dc_ga ~ "Hospital Discharge Gestational Age"
    ))%>%
  add_p() %>%
  bold_labels() %>%
  as_kable_extra(booktabs = T, escape = F, caption = "Demographics and Clinical Diagnosis in Infants") %>%
  kable_styling(font_size = 8)
```

# 3. Methods

## 3.1. Multiple Imputation

Multiple imputation will be used to address missing data. This method creates several imputed datasets, introducing variability in the imputed values to reflect the uncertainty around the true values. The imputation phase involves applying algorithms repetitively to generate values for the missing data. Subsequently, in the analysis phase, each dataset undergoes standard statistical analysis as though it were complete. The final phase, pooling, aggregates the results from all datasets, yielding parameter estimates that incorporate the variability across the imputations. In this project, models are fitted to 5 complete datasets, and the resulting estimates are then pooled, thus derivating final models.

## 3.2. Models

In this project, we compare two models: best subset selection and lasso regression, using a mixed-effects model. For the best subset model, the fixed effects are initially selected through best subset selection. Lasso regression employs \textbf{glmmLasso} [@grollGlmmLassoVariableSelection2023] in R. These methods are classical approaches to variable selection, contributing to the creation of more efficient prediction models. The mixed-effects model incorporates fixed effects of the observed covariates and random effects associated with the intercepts for each center, thereby capturing the variability between centers. This mixed-effects approach is particularly well-suited for data characterized by random variability across different groups—in this project, medical centers. The birth weight is log-transformed to fit the scale.

Data are collected at four distinct time points: at birth, at 36 and 44 weeks postmenstrual age (PMA), and at discharge. The objective is to predict the composite outcome of tracheostomy or death and to determine the optimal timing for tracheostomy. To achieve this, we will develop models for two critical phases: 36 weeks and 44 weeks PMA. The primary outcome to be modeled is a binary variable — either the occurrence of tracheostomy or death versus neither event, so the logistic regression will be used: 

$$log\left(\frac{p}{1-p}\right) = \beta_0 + \beta_1x_1 + \beta_2x_2 + \ldots + \beta_nx_n.$$

The models will be subjected to a train-test split method, where they will be trained on 70% of the dataset and validated on the remaining 30%.

## 3.2.1 36 Weeks PMA Model

In constructing the model specific to the 36 weeks PMA time point, I excluded all variables that were assessed at 44 weeks. The remaining variables were then using best subset and lasso regression techniques, incorporating center as a random effect in the analysis. The new dataset has 20 covariates.

## 3.2.2 44 Weeks PMA Model

For the 44 weeks PMA model, a key consideration was the fact that many infants are typically discharged before reaching 44 weeks. Therefore, this model specifically focused on infants who remained hospitalized at this time point. It included all relevant variables assessed at birth, at 36 weeks, and at 44 weeks. Similar to the 36 weeks PMA model, variable selection was performed using best subset and lasso regression, again considering center as a random effect. The new dataset left with 572 observations and 26 covariates.

# 4. Results

```{r}
load("mice_test_36.RData")
load("mice_test_44.RData")
testdata_36_long <- mice::complete(data_36_df_mice_out.test,action="long") 
testdata_44_long <- mice::complete(data_44_df_mice_out.test,action="long")
load("bestsubset_36.RData")
load("bestsubset_44.RData")
load("lasso_36.RData")
load("lasso_44.RData")

```


```{r}
################################################
################ 36 weeks model ################
################################################

### Best subset

# ROC
roc_mod_bestsubset_36 <- roc(predictor = predict(mod_bestsubset_36, newdata = testdata_36_long, type="response"),
                     response = as.factor(testdata_36_long$Y),
                     levels = c(0,1), direction = "<")

p_roc_bestsubset_36 <- ggroc(roc_mod_bestsubset_36) +
  theme_grey(base_size = 22)

# Calibration
num_cuts <- 10
calib_data_36 <-  data.frame(prob = predict(mod_bestsubset_36, newdata = testdata_36_long, type="response"),
                          bin = cut(predict(mod_bestsubset_36, newdata = testdata_36_long, type="response"), 
                                    breaks = num_cuts),
                          class = testdata_36_long$Y)
calib_data_36 <- calib_data_36 %>% 
             group_by(bin) %>% 
             summarize(observed = sum(class)/n(), 
                       expected = sum(prob)/n(), 
                       se = sqrt(observed*(1-observed)/n()))

p_calib_bestsubset_36 <- ggplot(calib_data_36) + 
  geom_abline(intercept = 0, slope = 1, color="red") + 
  geom_errorbar(aes(x = expected, 
                    ymin = observed - 1.96*se, 
                    ymax = observed + 1.96*se), 
                colour="black", width=.01)+
  geom_point(aes(x = expected, y = observed)) +
  labs(x = "Expected Proportion", y = "Observed Proportion") + 
  theme_grey(base_size = 22)

# Brier Score
bs_mod_bestsubset_36 <- mean((predict(mod_bestsubset_36, newdata = testdata_36_long, type="response") - testdata_36_long$Y)^2)
```

```{r}
### Lasso
# ROC
roc_mod_lasso_36 <- roc(predictor = predict(mod_lasso_36, newdata = testdata_36_long, type="response"),
                             response = as.factor(testdata_36_long$Y),
                             levels = c(0,1), direction = "<")

p_roc_lasso_36 <- ggroc(roc_mod_lasso_36) +
  theme_grey(base_size = 22)

# Calibration
num_cuts <- 10
calib_data_36 <-  data.frame(prob = predict(mod_lasso_36, newdata = testdata_36_long, type="response"),
                             bin = cut(predict(mod_lasso_36, newdata = testdata_36_long, type="response"), 
                                       breaks = num_cuts),
                             class = testdata_36_long$Y)
calib_data_36 <- calib_data_36 %>% 
  group_by(bin) %>% 
  summarize(observed = sum(class)/n(), 
            expected = sum(prob)/n(), 
            se = sqrt(observed*(1-observed)/n()))

p_calib_lasso_36 <- ggplot(calib_data_36) + 
  geom_abline(intercept = 0, slope = 1, color="red") + 
  geom_errorbar(aes(x = expected, 
                    ymin = observed - 1.96*se, 
                    ymax = observed + 1.96*se), 
                colour="black", width=.01)+
  geom_point(aes(x = expected, y = observed)) +
  labs(x = "Expected Proportion", y = "Observed Proportion") + 
  theme_grey(base_size = 22)

# Brier Score
bs_mod_lasso_36 <- mean((predict(mod_lasso_36, newdata = testdata_36_long, type="response") - testdata_36_long$Y)^2)

```


```{r}
################################################
################ 44 weeks model ################
################################################

### Best subset
# ROC
roc_mod_bestsubset_44 <- roc(predictor = predict(mod_bestsubset_44, newdata = testdata_44_long, type="response"),
                     response = as.factor(testdata_44_long$Y),
                     levels = c(0,1), direction = "<")

p_roc_bestsubset_44 <- ggroc(roc_mod_bestsubset_44) +
  theme_grey(base_size = 22)

# Calibration
num_cuts <- 10
calib_data_44 <-  data.frame(prob = predict(mod_bestsubset_44, newdata = testdata_44_long, type="response"),
                          bin = cut(predict(mod_bestsubset_44, newdata = testdata_44_long, type="response"), 
                                    breaks = num_cuts),
                          class = testdata_44_long$Y)
calib_data_44 <- calib_data_44 %>% 
             group_by(bin) %>% 
             summarize(observed = sum(class)/n(), 
                       expected = sum(prob)/n(), 
                       se = sqrt(observed*(1-observed)/n()))

p_calib_bestsubset_44 <- ggplot(calib_data_44) + 
  geom_abline(intercept = 0, slope = 1, color="red") + 
  geom_errorbar(aes(x = expected, 
                    ymin = observed - 1.96*se, 
                    ymax = observed + 1.96*se), 
                colour="black", width=.01)+
  geom_point(aes(x = expected, y = observed)) +
  labs(x = "Expected Proportion", y = "Observed Proportion") + 
  theme_grey(base_size = 22)

# Brier Score
bs_mod_bestsubset_44 <- mean((predict(mod_bestsubset_44, newdata = testdata_44_long, type="response") - testdata_44_long$Y)^2)
```

```{r}
### Lasso
# ROC
roc_mod_lasso_44 <- roc(predictor = predict(mod_lasso_44, newdata = testdata_44_long, type="response"),
                             response = as.factor(testdata_44_long$Y),
                             levels = c(0,1), direction = "<")

p_roc_lasso_44 <- ggroc(roc_mod_lasso_44) +

  theme_grey(base_size = 22)

# Calibration
num_cuts <- 10
calib_data_44 <-  data.frame(prob = predict(mod_lasso_44, newdata = testdata_44_long, type="response"),
                             bin = cut(predict(mod_lasso_44, newdata = testdata_44_long, type="response"), 
                                       breaks = num_cuts),
                             class = testdata_44_long$Y)
calib_data_44 <- calib_data_44 %>% 
  group_by(bin) %>% 
  summarize(observed = sum(class)/n(), 
            expected = sum(prob)/n(), 
            se = sqrt(observed*(1-observed)/n()))

p_calib_lasso_44 <- ggplot(calib_data_44) + 
  geom_abline(intercept = 0, slope = 1, color="red") + 
  geom_errorbar(aes(x = expected, 
                    ymin = observed - 1.96*se, 
                    ymax = observed + 1.96*se), 
                colour="black", width=.01)+
  geom_point(aes(x = expected, y = observed)) +
  labs(x = "Expected Proportion", y = "Observed Proportion") + 
  theme_grey(base_size = 22)

# Brier Score
bs_mod_lasso_44 <- mean((predict(mod_lasso_44, newdata = testdata_44_long, type="response") - testdata_44_long$Y)^2)
```

## 4.1. Model Coefficients

Table 5 presents the selected variables and their corresponding coefficients, as identified by the best subset and lasso regression methods within mixed-effects models, across five imputed datasets. These models account for center as a random effect. Notably, the best subset method tends to select fewer variables compared to the lasso regression models.

In terms of birth statistics, variables including ethnicity, prenatal steroids, and maternal chorioamnionitis are consistently selected across all models. Ethnicity and Prenatal Steroids are associated with positive coefficients in these models. However, the influence of Maternal Chorioamnionitis varies: it shows positive coefficients in the 36-week models and negative coefficients in the 44-week models.

For 36-week models, there are several common variables between the best subset and lasso models, including ventilation support level, fraction of inspired oxygen, and peak inspiratory pressure (measured in cmH2O) assessed at 36 weeks.

The 44-week models select a broader range of variables. These include birth statistics like gender, delivery method, and prenatal corticosteroids. Additionally, several parameters measured both at 36 and 44 weeks, such as weight, ventilation support level, fraction of inspired oxygen, and medication for pulmonary hypertension, are commonly included in these models.

```{r}
coef_bs_36 <- fixef(mod_bestsubset_36)
coef_bs_44 <- fixef(mod_bestsubset_44)
coef_lasso_36 <- coef(mod_lasso_36)
coef_lasso_44 <- coef(mod_lasso_44)
```

```{r}
all_names <- unique(c(names(coef_bs_36), names(coef_bs_44), 
                      names(coef_lasso_36), names(coef_lasso_44)))
coef_df <- data.frame(matrix(NA, nrow = length(all_names), ncol = 4))
colnames(coef_df) <- c("Best Subset 36 Week", "Best Subset 44 Week",
                       "Lasso 36 Week", "Lasso 44 Week")
rownames(coef_df) <- all_names

for (name in all_names) {
  if (name %in% names(coef_bs_36)) {
    coef_df[name, "Best Subset 36 Week"] <- coef_bs_36[name]
  }
  if (name %in% names(coef_bs_44)) {
    coef_df[name, "Best Subset 44 Week"] <- coef_bs_44[name]
  }
  if (name %in% names(coef_lasso_36)) {
    coef_df[name, "Lasso 36 Week"] <- coef_lasso_36[name]
  }
  if (name %in% names(coef_lasso_44)) {
    coef_df[name, "Lasso 44 Week"] <- coef_lasso_44[name]
  }
}

coef_df <- round(coef_df, 4)
coef_df[is.na(coef_df)] <- ""
```

```{r}
coef_df %>%
  kable(booktabs = T, escape = T, caption = "Summary for coefficients") %>%
  kable_styling(latex_options = c("scale_down")) %>%
  landscape()
```

## 4.2. Model Comparsion and Evaluation
Since the outcome of the model is binary, Brier score and area under the curve (AUC) are used to evaluate the models on the test datasets, which represent 30% of the data excluding the training set. AUC can be used to compare their discrimination ability, which is the ability of the model to differentiate between people with and without the outcome. Table 4 displays the summary statistics. The Best Subset model at 36 weeks demonstrated a Brier Score of 0.0835, an AUC of 0.8920, a decision threshold at 0.1600, along with a specificity of 0.8215 and a sensitivity of 0.8638. In comparison, the Best Subset model at 44 weeks showed a slightly higher Brier Score of 0.0963 and a higher AUC of 0.8961, with a notably higher threshold of 0.3015, a greater specificity of 0.9209, but a lower sensitivity of 0.7722. The Lasso model at 36 weeks exhibited a Brier Score of 0.0881, an AUC of 0.8736, a threshold of 0.1621, with specificity and sensitivity closely mirroring those of the Best Subset 36 Weeks model. Lastly, the Lasso model for 44 weeks registered a Brier Score of 0.0923, an AUC of 0.8853, the lowest threshold at 0.1281, a specificity identical to the 36 Weeks Lasso model, and the highest sensitivity of 0.8833 among all models.

In order to further compare these models in a intuitive way, the calibration and the receiver operating characteristic (ROC) curve are plotted in Figure 1. Calibration assesses the agreement between observed event frequencies and predicted probabilities. It is visualized through a calibration plot, which contrasts the predicted probabilities against observed event rates, illustrating how well the predictions match actual outcomes. It can be seen that the Lasso model at 36 weeks PMA seems to be closest to the 45-degree line, while both models at 44 weeks PMA exhibit some deviations, suggesting less calibration ability.

```{r}
# AIC, BIC, Brier & AUC
df_mod <- rbind(Brier = round(c(bs_mod_bestsubset_36, bs_mod_bestsubset_44, bs_mod_lasso_36, bs_mod_lasso_44),4),
                AUC = round(c(roc_mod_bestsubset_36$auc,
                              roc_mod_bestsubset_44$auc,
                              roc_mod_lasso_36$auc,
                              roc_mod_lasso_44$auc),4),
                Threshold = round(as.numeric(c(coords(roc_mod_bestsubset_36, "best")[1],
                                    coords(roc_mod_bestsubset_44, "best")[1],
                                    coords(roc_mod_lasso_36, "best")[1],
                                    coords(roc_mod_lasso_44, "best")[1])), 4),
                Specificity = round(as.numeric(c(coords(roc_mod_bestsubset_36, "best")[2],
                                    coords(roc_mod_bestsubset_44, "best")[2],
                                    coords(roc_mod_lasso_36, "best")[2],
                                    coords(roc_mod_lasso_44, "best")[2])), 4),
                Sensitivity = round(as.numeric(c(coords(roc_mod_bestsubset_36, "best")[3],
                                    coords(roc_mod_bestsubset_44, "best")[3],
                                    coords(roc_mod_lasso_36, "best")[3],
                                    coords(roc_mod_lasso_44, "best")[3])), 4))

colnames(df_mod) <-  c("Best Subset 36 Weeks", "Best Subset 44 Weeks",
                       "Lasso 36 Weeks", "Lasso 44 Weeks")
rownames(df_mod)[1] <- "Brier Score"

kable(df_mod, booktabs = T, escape = T, 
      caption = "Metircs for the models") %>% 
  kable_styling(latex_options = c("HOLD_position"))
```

```{r fig.height=12, fig.width=24, fig.align='center', fig.cap="Calibration Plots and ROC Curves for the Models"}
# Combine the plots
comb_plot <- ggarrange(p_calib_bestsubset_36, p_roc_bestsubset_36, 
                       p_calib_bestsubset_44, p_roc_bestsubset_44,
                       p_calib_lasso_36, p_roc_lasso_36, 
                       p_calib_lasso_44, p_roc_lasso_44,
                       ncol = 4, nrow = 2)
annotate_figure(comb_plot,
                top = text_grob("36 Weeks Model                                                                                                               44 Weeks Model", face = "bold", size = 22),
                left = text_grob("Lasso                                                          Best Subset", face = "bold", size = 22, rot = 90))
```

# 5. Discussion

The results show that the prediction models using center as a random effect to predict the composite outcome of tracheotomy/death on premature infants with BPD perform well.  Both the best subset and lasso regression models exhibit high accuracy at the two critical time points of 36 and 44 weeks. In the exploratory analysis highlights significant variations in demographic statistics and treatment methodologies across different centers, with some adopting more aggressive strategies or catering to patient profiles requiring such interventions.

The commmon variables used across these models, such as prenatal steroids, and maternal chorioamnionitis at birth assessment, ventilation support level, fraction of inspired oxygen, and peak inspiratory pressure (measured in cmH2O) in the follow-up assessment might be vital for doctors to determine the whether to perform tracheotomy.

Moreover, to compare the models across the time point, it can be seen that more variables should be considered at 44 weeks than at the 36 weeks. This variance at different time points suggests that these different variables like medication for pulmonary hypertension are critical for determining the tracheostomy's timing. The variation in coefficients for common variables between the 36-week and 44-week models also indicates changing circumstances of the infants over time.

However, the models in this project are limited by certain assumptions required for logistic regression: the assumption of linearity, the influence of outliers, and the presence of multicollinearity. The four models do not include interaction terms to assess the linearity assumption. The residual plots seem to indicate the presence of some outliers, suggesting potential influential values. Furthermore, the ventilation support variables at 36 and 44 weeks have very high VIF values, indicating potential multicollinearity.

# 6. Conclusion

The exploratory data analysis and regression models used in this project offer a comprehensive understanding of the factors influencing the necessity and timing of tracheostomy in infants with severe BPD. The models highlight the significance of birth metrics, respiratory support requirements, and medication for pulmonary hypertension as pivotal indicators. However, it is crucial to recognize the limitations presented by logistic regression assumptions, which include the need for linearity, the absence of influential outliers, and multicollinearity, areas where the models require further improvement.

# References
